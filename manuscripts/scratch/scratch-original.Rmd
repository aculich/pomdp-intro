
Measuring and understanding collapse and over-exploitation of fisheries
world-wide remains an essential issue for the ecological sciences
[@Costello2016].  Effective management practices in marine ecosystems also
inform conservation and resource management in less well-studied
systems. 

<!-- Set up broad relevance of understanding this issue -->




Central to both fisheries research and
policy, including international agreements such as the United Nations
Law of the Sea [@UNCLOS1982], is the principle of  maximal sustainable yield (MSY).
MSY aims to maintain a population at a fixed population size which should result in
the greatest long-term harvest (often referred to as Biomass at MSY,
$B_{MSY}$). While the theory dates back to classic work
of 1950s such as Beverton [@Beverton1957] and Schaefer [@Schaefer1957]
in deterministic models, it is Reed 1979 paper [@Reed1979] which proves
that the intuitive result of the deterministic models remains the optimal
policy for maximizing expected value of a fishery subject to stochastic
growth (i.e. environmental noise). Reed's result has allowed management
to largely sidestep the complexity of optimal control of stochastic
systems.  


This has long begged the question: if stochastic growth can be
safely ignored in determining the optimal harvest, is the same true of
measurement error?  Thanks to recent computational advances for solving
the decision theory problem in the case of imperfect observations
(measurement error), we show that -- contrary to both the intuition
from Reed's result and previous, approximate solutions -- ignoring
measurement error can result in significant over-harvesting, decreased
economic returns, and the potential for complete collapse of the stock.

Some historical perspective is necessary to put this result in the
appropriate context with respect to both management practice as well
as previous research in optimal control of fisheries and other natural
systems under uncertainty.  When population growth
varies stochastically, any fixed annual harvest such as MSY is no longer optimal:
instead, management must respond by dynamically harvesting more in years
of high growth and less in years of low growth.  Reed's proof [@Reed1979]
nevertheless demonstrated that the optimal harvest can still be captured
by a simple rule: harvesting just enough to reduce the population back
down to $B_{MSY}$.  This result is known as a "constant-escapement" policy 
because the population escaping harvest is always the same, 
even while the harvest itself varies dynamically with each stochastic shock. 
Moreover, Reed shows that under some relatively generic assumptions, this escapement
is identical to that predicted by the deterministic theory  ($B_{MSY}$).
Because the optimal harvest policy in the deterministic theory follows directly
from the growth rate (just find the stock size for which recruitment function
is maximized, no need for dynamic programming), attention shifted to inferring
that state equation from data.  Our focus is not on inferring this state
equation, but on the subsequent step of: having done so, how does one determine
the optimal harvest policy while also accounting for measurement uncertainty? 
Previous attempts to address this issue over the past three decades
have relied on various approximations which have usually led to the paradox
that harvests should increase under additional measurement uncertainty, contrary 
to our intuition that we should respond to greater uncertainty with greater caution.
Using more recent optimal control algorithms first developed in the artificial
intelligence literature, we provide a solution which avoids such assumptions
and resolves this paradox in favor of common sense intuition.  

Despite it's generality, Reed's proof makes a subtle assumption which
reduces the the impact uncertainty and underlies his conclusion
that the deterministic intuition of an average MSY is still optimal in 
the stochastic case.
In Reed's construction, the manager measures the stock
size without error during each time step before setting the harvest policy.
An important consequence of this construction is that this model can
thus never lead to accidental extinction of the stock.
Researchers have long recognized the weakness of this assumption of
perfect knowledge of the stock size and have sought to understand how it
may impact the resulting management policy [@Ludwig1981].  Because there is no risk of
accidental extinction in this scenario, it is possible that the optimal
policy may be more aggressive than is warranted.  Unfortunately, due
to the complexity of the analysis required to account for measurement
uncertainty, this question has never been satisfactorily answered.
Moreover, previous attempts at an approximate solution have consistently
found the surprising conclusion that the Reed solution is usually less
aggressive (dictating higher escapement or lower catch quotas) than
attempts to account for measurement uncertainty.  We briefly review the
main results in the ecological and resource economics literature that
have attempted to address this through various approximations before
presenting our solution, which draws on substantial algorithmic advances
that have been made in other fields.

The important way in which perfect observations diminish the role of
uncertainty in the model of Reed [@Reed1979] was first recognized in the classic
work of Clark & Kirkwood [@Clark1986].  They acknowledge the importance of measurement
uncertainty to the optimal solution, while observing that if
this assumption was relaxed, the "difficulty of the problem increases
markedly." Instead, @Clark1986 consider a perfectly observed model in
which harvest takes place after stochastic recruitment but before the
stock is measured, making accidental extinction a possibility
should realized growth fall sufficiently short of expectation.
In this case, @Clark1986 demonstrate that the optimal solution deviates
from the constant escapement rule, with the resulting optimal
policy is often significantly less cautious than the constant escapement policy.
In certain cases, @Clark1986 demonstrate that harvesting to extinction
is actually optimal. Other recent work [@Holden2015; @Johnson2016] has taken 
a similar approach to @Clark1986 in which measurement becomes uncertain due to
stochastic stock dynamics occurring between measurement and harvest, which
can also suggest less conservative (higher harvest) escapement rates. 

Rougharden [@Roughgarden1996] take a complementary approach, introducing measurement
uncertainty but searching only for the optimal constant escapement,
despite presenting no evidence (and indeed contrary to @Clark1986)
that the optimal solution under this circumstance should be a
constant escapement policy. By applying the rule-of-thumb assumption
that the optimal policy can be expressed simply as a constant escapement
(or equivalently, target-stock), the set of possible policies is reduced
dramatically and the calculation is relatively trivial.  As expected,
this restriction results in a policy that is always more conservative (lower harvest) than
the Reed solution which ignores measurement error, but both economically
inefficient and, as we shall see later, still less conservative than
the truly optimal policy for large stocks.   Other studies 
have likewise attempted to include uncertainties in model parameters and measurements
by making this same assumption that a constant escapement solution is optimal and 
thus avoiding solving the full sequential decision optimization problem [@Ludwig1981; @Moxnes2003; @Engen1997].

Sethi et al. [@Sethi2005] seek to address
the limitations of @Roughgarden1996 by searching for the true optimal
policy without the strong assumption of constant escapement.
Like @Clark1986 and others, @Sethi2005 finds support for the counter-intuitive result
of an optimal policy that is significantly less cautious when accounting
for measurement uncertainty than the corresponding constant escapement
solution which ignores it. 
Unfortunately, the approach taken by @Sethi2005 once again avoids solving
the full optimal decision-making problem by means of a simplification
which we might term the amnesic assumption: during each subsequent
decision the manager forgets any previous knowledge of the system.
This allows them to use the standard Stochastic Dynamic Programming
(SDP) solution method used by @Reed1979 and @Clark1986. This method
assumes that problem in question is a Markov Decision Process (MDP):
one in which given the state $x$ and action $a$, the probability of a
transition to state $x'$ is conditionally independent of all previous
states and actions (known as the Markov property).  This holds only if the state
is known without error -- once we introduce any amount of measurement
uncertainty about the state $x$, the process with respect to the observed
state is no longer Markovian but depends on all previous observations.

This problem can be solved by considering
the 'belief' state rather than the observed state, which restores
the Markov property at the cost of much greater problem complexity:
one must consider a (continuously-valued) probability
that the system is in each of the $|X|$ possible states of such a 
Partially Observed Markov Decision Process (POMDP). This is the
key feature of the POMDP approach: all previous observations are
collectively reflected in this belief distribution, and decisions
are based not only on the most recent observation (as in MDP), but
are also influenced by this prior belief.  

The mechanics of 
updating these beliefs, while technical, have been well
illustrated elsewhere even in conservation applications
[e.g. @Lane1989; @Chades2008; @Haight2010; @Chades2011;
@Williams2011; @Springborn2013; @Fackler2014; @Fackler22014; @Baggio2016].
However, these previous studies have relied on relatively direct algorithms 
which are not amenable to the large number of states and actions required by the optimal
fisheries harvest problem.  By leveraging newer point-based algorithms developed in the artificial 
intelligence community [@Kurniawati2008; @Shani2013; see SI; R code], we are able to solve
the POMDP models for fisheries management directly. 
These solutions illustrate how incorporating the information
of all previous observations into a prior belief allows the
POMDP approach to handle measurement error which would 
cause a stock collapse under MDP or deterministic methods.
We also evaluate the performance of proposed method
on a real-world time series of population estimates of
marine ecosystems from RAM Legacy Stock
Assessment Database [@Ricard2011].

## Model formulation

Our formulation of the fisheries management problem closely follows that of 
earlier work [e.g. @Sethi2005], which we summarize here. Alternate formulations are provided in the SI,
illustrating that our conclusions are not constrained to these particular choices.

The fisheries manager seeks to maximize the expected net present value of the fishery
over an infinite time horizon under two sources of uncertainty: population dynamics (i.e. growth of the stock),
and stock measurements, given an model estimate of those dynamics:

\begin{equation}\label{optim}
\max_{\{h_t\} \geq 0} \mathbf{E} \left[ \sum_0^{\infty} \gamma^t U(x_t, h_t) \right]
\end{equation}


The state of the system, $x_t$ corresponds to the (true) fish stock at time $t$. 
The harvest is $h_t = \min \left(x_t,a_t\right)$, where $a_t$ is the attempted harvest at time step $t$.
For simplicity, we assume the reward (utility) is directly proportional to the
harvest, $U(x_t, h_t) = \min(h_t, x_t)$, with future rewards discounted by multiplicative discount factor $\gamma = 0.95$;
alternate harvest functions and alternate discount rate are considered in the SI. 

The population dynamics is formulated as:

\begin{equation}
x_t = \epsilon_{g} f(s_{t-1})
\end{equation}

where $s_{t-1} = x_{t-1} - h_{t-1}$ is the escapement at time $t-1$, and
$\epsilon_{g}$ corresponds to stochastic component of recruitment (growth noise). 

While it is theoretically possible to learn about this model and its parameters during the
decision process itself (so-called adaptive management, e.g. @Johnson2015 for MDP case; 
we discuss the potential for POMDP adaptive management in *Future Directions*), it is
typical to consider that state-space dynamics $f$ have been previously estimated from data.  
The goal of a decision process is to determine the optimal sequence of actions given this
model. From the population dynamics state
equation we derive a set of transition matrices $T(x_t, a_t, x_{t+1})$ describing the
probability of a transition from $x_t$ to $x_{t+1}$ under action $a_t$ (SI Methods).
While such transition matrices can be defined even when $f$ represents only a posterior
distribution of model parameter values [e.g. @Boettiger2015] or an age-structured 
model [e.g. @Holden2015], for simplicity of presentation we will focus on the case
in which $f$ is a fixed model with known parameters, given by the Ricker equation [@Ricker1954]:

\begin{equation}\label{ricker}
f(s_t) = s_t \exp\left(r \left(1-\frac{s_t}{K}\right)\right),
\end{equation}

where $K$ denotes the carrying capacity of the system, and $r$ the growth rate.
The optimal management of this model in the deterministic and growth-noise-only (MDP)
case is already well understood and thus will provide a useful foil against
which to examine the role of measurement uncertainty.  
To demonstrate that our results are not unique to this choice of \eqref{ricker}, two alternate models,
the Beverton-Holt model [@Beverton1957], and the Allen model [@Allen2005], are evaluated in the SI.

The POMDP problem is distinguished by the introduction of measurement error, in which 
the observed stock $z_t$ is measured with uncertainty, $z_t = \epsilon_{m} x_t$. 
In general this is defined by observation matrices $O(z_t, x_t, a_t)$ giving the 
probability of observing $z_t$ given a system in state $x_t$ and having taken action $a_t$,
though in our formulation this probability is independent of the action.

We will assume for simplicity that the stochastic growth noise $\epsilon_g$ and measurement error $\epsilon_m$ 
are distributed log-normally with mean $1$ and scale parameter $\sigma_{g}$ 
and $\sigma_m$ respectively. Larger $\sigma$ corresponds to higher variance,
scaled to be comparable to the uniform noise distribution shown in the SI,
(see *Materials and Methods*).  We evaluate the effect of
different noise levels in both growth and measurements, $\sigma_{g},
\sigma_{m} \in \{0, 0.1, 0.5\}$.

As the numerical solutions of the MDP and POMDP problems require discrete states,
we consider a system of 50 states on a uniform grid of 0 to 1 with $K = 0.66$ and
$r = 1$; (alternative growth rates shown in the SI).   
The transition matrices $T$, together with the observation matrix $O$ and the utility
function, completely specify a POMDP problem which can be solved with a numerical
algorithm (*Materials and Methods*).  




# Results {#results .unnumbered}

To illustrate the impact of measurement error on management outcomes,
we compare two scenarios: with measurement error ($\sigma_m = 0.5$,
see *Materials and Methods*) and without measurement error (Fig \ref{sim}).
In each scenario, we compute the optimal policy using three different
solution methods: POMDP, MDP, and a policy we refer to as Offline POMDP.
In POMDP, the optimal policy at each time point depends not only on the
most recent observation, but on the manager's prior belief of the state,
which depends on all prior observations. As such, the optimal POMDP
policy for a particular observation cannot be computed ahead of time
but must be calculated "online", as observations come in.  In contrast,
in MDP, the optimal policy depends only on the most recent observation.
The "Offline" policy uses the POMDP solution given a fixed, uniform
prior belief, rather than updating the prior belief over states after
each observation.  For each scenario (with and without measurement error), 
we generate 100 simulations of  the fishery being managed under each 
strategy (MDP, Offline, POMDP) for 100 time steps.  We compute the average and standard
deviation of the stock size over these 100 replicates, Fig. \ref{sim},
as well as the mean economic return of each case (Table \ref{Table1})
and the fraction of simulated stocks that have collapsed by the end
of the simulation (Table \ref{Table2}). While we perform these
simulations over a range of models, parameter values and noise distributions, for
simplicity of presentation we focus on simulations
from a Ricker model with log-normally distributed noise (see *Materials and Methods*);
comparable results under the alternative choices are presented in the SI.


\begin{figure}[h]
\centering
\caption{Forward simulations of managing a marine ecosystem under POMDP and MDP models in the presence ( $\sigma_m = 0.5$, top panel) or absence ( $\sigma_m = 0$, bottom panel) of measurement error.  Lines show the mean stock size over 100 replicate simulations, error bands show +/- 1 standard deviation.  Many of the replicate simulations under MDP quickly collapse the stock by over-harvesting when measurement error is present.  In contrast, the POMDP management is robust to the level of measurement error, avoiding stock collapse whether or not measurement error is actually present.  The growth model is Ricker, the noise is log-normally distributed, the carrying capacity of the system is $K = 0.66$, the maximum per capita growth rate is $r = 1$, growth noise is $\sigma_g = 0.5$, and the discount factor is $\gamma = 0.95$.}\label{sim}
\end{figure}

Fig. \ref{sim}, top panel, illustrates that ignoring or underestimating
the measurement error result in dramatic collapse of the stock and
significant loss in revenue: the mean MDP state declines as subsequent
replicate simulations collapse (94/100 collapse within 100 time steps)
when measurement error leads to over-harvesting.  The POMDP method
retains a steady, sustainable harvest that keeps the population below
carrying capacity but results in minimal population collapse (4/100). The
offline solution results in some stock collapse (34/100) as a result of
not updating the manager's belief state over subsequent observations.
Unsurprisingly, average economic returns are also much lower for MDP
when measurement error is present, returning an average of 66% of the net present value returned by
POMDP (Table \ref{Table1}), and would be lower still with less aggressive discounting of future
rewards (Here $\gamma = 0.95$ makes later collapses less relevant to the total).
Fig. S1 shows stock trajectories from several individual replicates, which 
show relatively little decline before collapsing suddenly when managed under MDP
when measurement error is present.  Averaging over an ensemble of such trajectories
gives the appearance of a smooth decline. 

On the other hand, overestimating measurement error might result in a
trivial loss in revenue but does not result in collapse of the stock,
(Fig. \ref{sim}, lower panel). In this scenario, since no
measurement error is present, the MDP solution is indeed optimal, but the
POMDP policy which assumes a measurement error of $\sigma_m = 0.5$ and
thus overestimates the measurement uncertainty performs nearly as well
(average of 94% of the MDP net present value and likewise no collapses of the stock, Table \ref{Table2}).
In the SI we report the same patterns for Ricker model
with uniform noise (Fig. S2), Beverton-Holt model with log-normal noise
(Fig. S3), and Allen model with log-normal noise (Fig. S4).


<!-- Perhaps in-text quotations of these numbers is sufficient?-->


\begin{table}
\centering
\caption{Ecological and economic performance when
measurement error is present, (\(\sigma_m = 0.5\))}
\begin{tabular}{lccc}
& MDP & Offline & POMDP \\
\midrule
Fraction collapsed & 94\% & 34\% & 4\% \\
Economic return & 66\% & 99\% & 100\% \\
\bottomrule
\end{tabular}
\label{Table1}
\end{table}

\begin{table}
\centering
\caption{Ecological and economic performance when
measurement are perfect, (\(\sigma_m = 0\))}
\begin{tabular}{lccc}
& MDP & Offline & POMDP \\
\midrule
Fraction collapsed & 0\% & 0\% & 0\% \\
Economic return & 100\% & 96\% & 94\% \\
\bottomrule
\end{tabular}
\label{Table2}
\end{table}



To facilitate comparison with previous research and management practice,
we plot the corresponding optimal action in terms of *expected escapement*: the
stock the manager expects will be left in the sea after harvest $z_t - h_t$.
Recall that introducing measurement error means that this value can differ
from realized escapement, $x_t - h_t$. Fig. \ref{policy} shows the optimal expected 
escapement as a function of observed stock sizes over a range of growth 
noise and observation error intensities, assuming a uniform prior belief over
states $x_t \in (0,1)$ for $\sigma_m > 0$. These policies are determined numerically
using the SARSOP algorithm for POMDP [ @Kurniawati2008], as discussed in *Materials and Methods* and
illustrated in the supplementary code provided.  

In the MDP case ($\sigma_m = 0$),
we see the classical result of constant escapement [@Reed1979], where the stock is harvested
back down to the same escapement regardless of observed stock or growth noise.
When growth noise is large ($\sigma_g = 0.5$) relative to measurement
error ($\sigma_m = 0.1$), the policy converges towards the the constant
optimal escapement solution of @Reed1979, as expected. These patterns
hold independent of the population growth model (e.g. Beverton-Holt and
Allen) and the shape of the noise distribution (Fig. S5--S6).
The most obvious difference between the MDP and POMDP policies arises in the region of
linear or nearly linear increases in expected escapement occurring at very large observed stock sizes,
which arises from any policy whose harvest remains *constant* over that range. Not increasing
harvest in response to higher observed stock sizes always result in a higher expected escapement, $z_t - h_t$.  
This corresponds to a policy which believes such high observations are almost surely the 
result of measurement error, and suggests that overestimated stock sizes are responsible for MDP
over-harvesting and the subsequent collapse of the stock. At smaller stock sizes, the policies
shown in Fig. \ref{policy} appear more similar over any measurement error, but in fact this is only a consequence of the
uniform prior belief. While Fig. \ref{policy} completely specifies the management policy under MDP,
this is not true for the POMDP solutions ($\sigma_m > 0$), which also depend on all
prior observations through the influence of the belief state.  

\begin{figure}[h]
\centering
\caption{Optimal escapement policy as a function of measured stock for Ricker model, with different measurement errors and growth noise. Noises are log-normally distributed, and the prior belief state is uniform among all stocks. The carrying capacity of the system is $K = 0.66$, the growth rate is $r = 1$ and the discount factor is $\gamma = 0.95$.}\label{policy}
\end{figure}


To illustrate this key difference, we plot (Fig. \ref{bel})
the POMDP policy under two alternative prior belief states: (1) Low
Stock: where the prior belief is centered at $x = 0.2$ , and (2) High Stock:
where the prior belief is centered at the location of carrying capacity $x =
0.66$. This figure is generated in an identical manner to Fig. \ref{policy} 
except for the different choice of prior belief.  Visualizations of these 
prior distributions are shown in Fig. S12. When the prior belief skews towards low stocks, the
probability that an observation of a high stock is an overestimate due to
measurement error is greater, and consequently the policy becomes more conservative
(higher escapement). This ability to incorporate the knowledge from prior
observations accounts for the difference
in performance between the POMDP solution and the Offline solution in
Fig. \ref{sim} when measurement error is present. 
The evolution of the belief state in response to subsequent observations
over a given simulation is shown for the different models in Figs S14 - S16.
Corresponding plots for alternate models are shown in Fig. S9.
The patterns shown here are further robust to the reward function (including
linear cost to harvest and a diminishing returns model, Fig. S8) and the
discount rate Fig. S13. 

\begin{figure}[h]
\centering
\caption{Optimal escapement policy as a function of measured stock and different prior belief states: (1) Uniform: uniform prior belief over all stocks, (2) Low Stock: the prior belief is centered at $x = 0.2$, and (3) High Stock: the prior belief is centered at the location of carrying capacity $x =
0.66$. In this figure, growth model is Ricker, measurement and growth noises are $\sigma_m = \sigma_g = 0.5$, and are log-normally distributed, the growth rate is $r = 1$, and the discount factor is $\gamma = 0.95$.}\label{bel}
\end{figure}


## Application to real-world fisheries

Using historical time series of Argentine Hake on the Patagonian Shelf and
European Plaice on the Celtic-Biscay Shelf from the the RAM Legacy Stock
Assessment database [@Ricard2011], we compare the catch levels recommended
by POMDP and MDP methods against historical values (Fig. \ref{RAM2}). We have selected
these two examples for having both adequately long records and show very
different trends in both population biomass and catch. We non-dimensionalize
the data and then use Maximum
Likelihood Estimation (MLE) through NIMBLE [@nimble-software:2016] to
fit a Ricker model for both these examples (details of MLE fits can be
found in the SI). Based on this model estimate, we then determine MDP
and POMDP policies using the appropriate algorithms.  In the case of MDP,
the optimal harvest is determined directly from that year's estimated
stock abundance.  In the case of POMDP, the optimal harvest depends both
on this stock estimate and the prior belief, which is sequentially updated
based on each previous observation (stock estimate) and action (catch).

Both examples illustrate the contrast between the ignoring (MDP) and accounting for measurement error (POMDP).
The POMDP solution tends to recommend a lower harvest than the MDP solution
in both cases, but not strictly so.  In Plaice example, we see the the POMDP solution is less 
volatile, increasing harvest more modestly in response to observing stock 
sizes while fishing pressure remains constant or increases (e.g. 1980-1990), 
while also decreasing less if stocks decline under constant or decreasing fishing
pressure (e.g. 1990-2000). Under the MDP model, only sharp changes in catch
can drive these sharp shifts in stock levels, while the POMDP model permits that these
can arise in part by measurement error and thus require less volatility in the harvest. 
In the Hake time series, the continued decline of the stock leads both MDP
and POMDP solutions to recommend smaller harvests than historically observed.
Again the POMDP solution is less volatile than the MDP, starting with a more
modest harvest at the beginning of the time-series (where a uniform prior over
states is assumed), and at first decreasing more gradually but then retaining
the moratorium on fishing when a small rebound (circa 2005) leads the MDP to a
renewed harvest.  


\begin{figure}[h]
\centering
\caption{This figure compares the actual stock biomass and catch of European Plaice on the Celtic-Biscay Shelf and Argentine Hake on the Patagonian Shelf with actions suggested by MDP and POMDP frameworks. In the case of POMDP we have used measurement error of $\sigma_m = 0.5$.}\label{RAM2}
\end{figure}


# Discussion {#discussion .unnumbered}

We have shown that fully accounting for measurement error in calculating
the optimal fishing harvest leads to management that is usually more conservative
(higher expected escapement) as the measurement error increases. This
contrasts with the classic solution of constant escapement, in which
larger estimates of the stock size justify proportionally larger harvests.
The importance of our intuitively sensible conclusion is underscored
by the contrast to both much of current fisheries management practice
and previous research into measurement uncertainty.  Most fishing policy
still reflects the results @Reed1979 driven in
the absence of measurement error, and even much previous work on the role
of measurement uncertainty  has either assumed constant escapement-type
solutions [@Roughgarden1996; @Moxnes2003; @Engen1997] or relied on approximations which
have argued that accounting for measurement uncertainty should result
in an *increased* harvest (lower target stock size) [@Ludwig1981; @Clark1986; @Sethi2005].  

Using simulations (Fig. \ref{sim}, S2-S4), we have shown that failing to account for measurement error
can lead to dramatic ecological and economic consequences. MDP solutions, which
ignore measurement error, collapse 94% of simulated time series within 100 time
steps. This does not mean that measurement error in the simulations is so large
as to make informed management impossible -- in fact the optimal POMDP solution,
which accounts for measurement error, experiences a collapse in only 4% of
simulations shown here. While the precise degree of measurement uncertainty may
itself be unknown, these results also show that it is better to overestimate
than underestimate this uncertainty. Even when no measurement error is present,
a POMDP solution which assumes a large measurement error ($\sigma_m = 0.5$) performs
nearly as well as the optimal MDP solution in all of our simulations. Fig. \ref{policy}
and \ref{bel} provide the intuition behind why MDP approach results in such a high probability
of collapse: when measurement error results in a chance over-estimation of the 
stock, the resulting harvest under MDP can be much larger than under POMDP. A single
large or a few consecutive smaller over-estimations of the stock size can thus 
quickly drive the stock to zero.  In contrast, the POMDP solution will harvest
much less under the same observation error, particularly when it compares that
observation against the accumulated prior belief that the current state should
be lower, Fig \ref{bel}.

We have shown that this dramatic reduction in the probability of a 
collapse is not trivially the result of a more cautious strategy; e.g. one which always
harvests less than MDP.  Rather, it is the result of a making full use
of all of the data through the role of the belief state.
The POMDP solution, unlike the MDP solution, depends on
the entire history of previous observations, which inform the current
belief state.  As shown in Fig \ref{bel}, this can correspond
to higher harvests if prior observations give sufficient evidence that 
the stock is higher than suggested by the most recent measurement. As a result,
the POMDP policy can outperform the MDP policy economically as well as 
ecologically. 

We have also demonstrated these patterns by comparing harvests recommended
by MDP methods against those recommended by POMDP methods using two separate
historical time series.  These examples provide a further illustration
of how accounting for measurement uncertainty results in very different policy
outcomes than ignoring it.  Note that this analysis does not seek to explain
the differences between either the MDP and POMDP solutions from the historical
catches actually observed.  While it is very possible that the observed harvests
were governed by some sort of constant-escapement policy, actual catch quotas
or other policy information is not available in this data. Fluctuations in historical
harvest may reflect many other factors than such a policy, such as different stock
models, external constraints such as the cost of adjusting policy [@Boettiger2016], 
or other economic, political or environmental factors.  While we are free to
make comparisons between MDP and POMDP solutions on the historical data, understanding
why historical harvests differed from either of these would need an understanding of 
these contextual issues that are beyond our data and our scope here.
Given the stock-recruitment model for the fishery, the MDP optimum harvest depends only
on the most recent stock estimate, while both the full time series of historical harvests
and historical stock estimates influence the POMDP optimum, by altering the belief
state at the time.  We have
relied on estimating reasonable candidate models and parameters from the time series
a priori (specifically MLE parameters to the Ricker model). Ideally model
and parameters would also be inferred over the course of the sequential decisions,
which would integrate over such uncertainty in models or parameters.
While MDP methods to address these issues of model uncertainty
and parameter uncertainty have been developed elsewhere [e.g. @Johnson2015] this remains
a subject for future research in POMDP applications (see *Future directions*).

We have shown that our result is generally robust to our assumptions:
this pattern holds for differing models (Ricker, Beverton-Holt, and Allen),
differing magnitudes and also different shapes of noise distributions
(log-normal, as considered by @Clark1986 or uniform, as considered by
@Sethi2005), the choice of the reward/profit equation, or the details of
the discretization (see SI).  This robustness is not surprising, being consistent
with sensitivity observed in previous work.  Indeed, in the absence of
measurement error most of these scenarios were already covered by Reed's
proof, (with the exception of the Allen model whose change in concavity
violates the theorem and likewise shows deviations here).
Thus it is perhaps all the more surprising that
constant escapement is not robust to the assumption of measurement error.

The optimization approach considered here can be distinguished from more heuristic
approaches to address the uncertainty, such as pretty good yield (PGY)[@Hilborn2010; @Rindorf2016] or management strategy evaluation (MSE).  Methods based on MSE have been applied in fishery management for providing the decision maker with a rationale to base their decisions given their specific optimization objectives [@Smith1994; @Mapstone2008; @Bunnefeld2011]. The main difference between MSE and methods based on dynamic programming is that MSE does not solve the optimization problem to provide the optimal strategy, rather it evaluates consequences of a set of strategies defined based on management objectives and provides the outcome of those simulations to the decision maker. In that sense, MSE can be compared to the policy evaluation step of optimization in dynamic programming using policy iteration methods [@Sutton1998], while the policy improvement step is being ignored due to computational complexity. With advancements in efficient solving of dynamic programming optimization under several sources of uncertainty [@Shani2013], the traditional MSE approach can be interpreted as an internal step in the optimization process that tries to identify the best management strategy, searching through all viable and possible strategies. MSE can be also compared to Monte Carlo search algorithms within the space of possible policies that the manager can explore and evaluating the policies based on the outcome [@Smith1999]. For example, @Smith1999 evaluates the effect of several sources of uncertainty such as structural and parameter uncertainty in the models, errors in data and observation systems, estimation uncertainty, and management implementation uncertainty in partnership with Australian Fisheries Management Authority.


Our results have important implications for management of fisheries.
The most evident of these is that given the unavoidable realities of measurement
error in stock estimates, the wide use of management based on constant-escapement
solutions and derivative concepts such as maximum sustainable yield (MSY), maximum
sustainable biomass ($B_{MSY}$),
which are central to scientific fisheries management and policy
included the United Nations Law of the Sea [@UNCLOS1982], are insufficient to
guarantee either maximum sustainable economic yield or persistence of fish stocks.
Instead, target harvest or target escapement must reflect current and previous 
stock estimates and the degree of measurement uncertainty present. While precise 
estimates of the uncertainty in measurements, $\sigma_m$ may be difficult to obtain,
we have shown that it better both ecologically (in the probability of stock collapse)
and economically (in the profits from fishing) to overestimate than underestimate this
quantity.


This important qualitative impact that measurement error has on the
optimal solution of an important and well-studied ecological management
problem has more general implications.  The role of measurement error
is most often acknowledged in the breach -- a mathematically
convenient assumption only.  After all, inherent stochasticity has often been found
to make only small differences from deterministic solutions, as @Reed1979
proved in this case. Our result demonstrates how frail such an assumption
regarding measurement uncertainty may be, particularly when determining
optimal policy.  No doubt the mathematical and computational difficulty of
accounting for measurement uncertainty has forestalled greater attention
to this issue.  The growing wave of available data makes such concerns
about measurement error all the more pressing, as imperfect but readily
available observations make such data-driven optimization possible in more
applications. 

These results have both tactical and strategic implications for ecological 
modeling and fisheries management [sensu @May1973]. At a strategic level,
this highlights the danger in ignoring the potentially asymmetric impact of
measurement error, which can lead to significant over-harvesting and potential
collapse of the stock.  At a tactical level, the precise amount by which
harvest should be adjusted to account for a given measurement error to maximize
the expected value of a stock will require a POMDP solution for the specific 
fishery in question, which is now computationally feasible using the approach
we have presented here. We hope that the recent advances in efficient and accurate
POMDP solvers, together with greater attention to these challenges,
will encourage a wider consideration of the role of measurement error
in determining appropriately precautionary management policy.

In conclusion, we have demonstrated the importance of measurement error
in the long-standing question of optimal harvests in fisheries.  We have 
shown that overestimating the measurement error can still result in policies
that are nearly optimal both economically and ecologically, while ignoring or
underestimating the measurement noise can cause dramatic collapses of fish
stocks even when no tipping point is present.  This suggests that the failure
to account for measurement error in this way in even the most advanced 
fisheries management could contribute to long-term trends in declining
stocks [e.g. @Costello2016]. We believe the approach taken
here both highlights the importance of accounting for measurement error and
provides an example of how this can be accomplished in the POMDP framework
using modern algorithms on complex problems. We have also implemented the
proposed method on a real-world problem of managing a marine ecosystem and show
that the policy suggested by POMDP is significantly different with respect to the
actual catch landings.

## Future directions

Several limitations that have been studied in MDP models, such as parameter 
and model uncertainty and adaptive management [e.g. @Johnson2015] remain
intriguing future challenges for POMDP problems. Future work could extend the examples
shown here to include more realistic models, such as those with age structure, as
has only recently been done for the MDP case [@Holden2015].
There remains a need for further improvement of the proposed method to include such model uncertainty. 
Previous attempts that adapt POMDP tools to include model uncertainty [i.e. @Chades2012] have had to
assume full observability of state space, ignoring measurement uncertainty. 
A second limiting assumption common to MDPs and POMDPs is that of stationary dynamics: 
that the population dynamics equation itself is not changing over
time. In reality, forces such as climate change and other forms of environmental variations violate this
assumption. @Fackler22014 attempts to address this problem by 
adaptation of Mixed Observability MDP [@Ong2010] framework, although the proposed algorithm
for finding optimal solution to such non-stationary systems is intractable, except for 
extremely simplified examples used in that study. Our future work involve relaxing
these assumptions by proposing computationally feasible approximate algorithms within the 
POMDP framework to deal both with model uncertainty and non-stationarity of system's dynamics.
Lastly, the introduction of POMDP approaches raises a central question for managers: when is it
worthwhile to actively reduce measurement error to derive a better policy, and when is it
best simply to account for current measurement error?  This issue can be addressed through
a Value of Information framework, as @Johnson2015 illustrates in the case of MDPs.


# Materials and Methods {#methods .unnumbered}

A Partially Observed Markov Decision Process (POMDP) [@Smallwood1973;
@Sondik1978] is a generalization of a Markov Decision Process (MDP),
which is a fundamental model for sequential decision making.  In the
ecological literature, MDPs are often referred to by their solution
method: Stochastic Dynamic Programming [SDP see @Marescot2013].
The MDP approach has been widely used in behavioral ecology
[@Mangel1988] as well as conservation ecology and resource economics
[e.g. @Mangel1985]. Introductions to MDP and solving them through dynamic
programming are provided in @Mangel1985, @Bertsekas1996 and @Sutton1998.
Specifically, POMDPs overcome one of the main limitations of MDP which
is the assumption about the full observability of the system's state.
In POMDP, the exact state of the system cannot be
observed directly, but can be inferred by indirect measurements.
POMDPs can be represented as a probabilistic graphical models
[@Barber2012] as in Fig. S11.  For further details regard POMDP framework,
its parameters, and details of solving the optimization problem,
refer to the SI. 

Our approach utilizes the SARSOP algorithm of @Kurniawati2008. Computational 
requirements are still significantly more demanding than the equivalent MDP solution.
Precise computational time and memory requirements depend not only on system size but on
the precision requested of the approximate, point-based solution. Reasonable
solutions for the problems considered here can be reached within an hour of computation,
though were run for five hours each to confirm convergence. 
As a supplement to this paper we provide example scripts for replicating
the analyses shown here, which can be found at https://github.com/boettiger-lab/sarsop.